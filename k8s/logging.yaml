# Elasticsearch部署
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: medical-ai
spec:
  serviceName: elasticsearch
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
        ports:
        - containerPort: 9200
          name: rest
        - containerPort: 9300
          name: inter-node
        env:
        - name: cluster.name
          value: medical-ai-logs
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: discovery.seed_hosts
          value: "elasticsearch-0.elasticsearch,elasticsearch-1.elasticsearch,elasticsearch-2.elasticsearch"
        - name: cluster.initial_master_nodes
          value: "elasticsearch-0,elasticsearch-1,elasticsearch-2"
        - name: ES_JAVA_OPTS
          value: "-Xms2g -Xmx2g"
        - name: xpack.security.enabled
          value: "false"
        - name: xpack.monitoring.collection.enabled
          value: "true"
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        volumeMounts:
        - name: elasticsearch-data
          mountPath: /usr/share/elasticsearch/data
        livenessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 30
          periodSeconds: 10
  volumeClaimTemplates:
  - metadata:
      name: elasticsearch-data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 50Gi
---
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: medical-ai
spec:
  clusterIP: None
  selector:
    app: elasticsearch
  ports:
  - port: 9200
    name: rest
  - port: 9300
    name: inter-node
---
# Kibana部署
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: medical-ai
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:8.11.0
        ports:
        - containerPort: 5601
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elasticsearch:9200"
        - name: SERVER_NAME
          value: "kibana"
        - name: SERVER_HOST
          value: "0.0.0.0"
        - name: XPACK_SECURITY_ENABLED
          value: "false"
        - name: XPACK_MONITORING_UI_CONTAINER_ELASTICSEARCH_ENABLED
          value: "true"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /api/status
            port: 5601
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /api/status
            port: 5601
          initialDelaySeconds: 30
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: kibana
  namespace: medical-ai
spec:
  selector:
    app: kibana
  ports:
  - port: 5601
    targetPort: 5601
  type: ClusterIP
---
# Logstash部署
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash
  namespace: medical-ai
spec:
  replicas: 2
  selector:
    matchLabels:
      app: logstash
  template:
    metadata:
      labels:
        app: logstash
    spec:
      containers:
      - name: logstash
        image: docker.elastic.co/logstash/logstash:8.11.0
        ports:
        - containerPort: 5044
        - containerPort: 9600
        env:
        - name: LS_JAVA_OPTS
          value: "-Xmx1g -Xms1g"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi
        volumeMounts:
        - name: logstash-config
          mountPath: /usr/share/logstash/pipeline
        - name: logstash-settings
          mountPath: /usr/share/logstash/config
        livenessProbe:
          httpGet:
            path: /
            port: 9600
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: 9600
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: logstash-config
        configMap:
          name: logstash-config
      - name: logstash-settings
        configMap:
          name: logstash-settings
---
apiVersion: v1
kind: Service
metadata:
  name: logstash
  namespace: medical-ai
spec:
  selector:
    app: logstash
  ports:
  - port: 5044
    name: beats
  - port: 9600
    name: http
---
# Fluentd DaemonSet
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: medical-ai
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      serviceAccountName: fluentd
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1.16-debian-elasticsearch7-1
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name: FLUENT_ELASTICSEARCH_SCHEME
          value: "http"
        - name: FLUENTD_SYSTEMD_CONF
          value: disable
        - name: FLUENT_CONTAINER_TAIL_EXCLUDE_PATH
          value: /var/log/containers/fluent*
        - name: FLUENT_CONTAINER_TAIL_PARSER_TYPE
          value: /^(?<time>.+) (?<stream>stdout|stderr)( (?<logtag>.))? (?<log>.*)$/
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
          limits:
            cpu: 500m
            memory: 500Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: fluentd-config
          mountPath: /fluentd/etc
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: fluentd-config
        configMap:
          name: fluentd-config
---
# Fluentd ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: medical-ai
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluentd
rules:
- apiGroups: [""]
  resources:
  - pods
  - namespaces
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluentd
roleRef:
  kind: ClusterRole
  name: fluentd
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: medical-ai
---
# Logstash配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-config
  namespace: medical-ai
data:
  logstash.conf: |
    input {
      beats {
        port => 5044
      }
      
      # 接收来自应用的日志
      http {
        port => 8080
        codec => json
      }
    }
    
    filter {
      # 解析Kubernetes日志
      if [kubernetes] {
        mutate {
          add_field => { "cluster" => "medical-ai" }
        }
        
        # 解析容器日志
        if [kubernetes][container_name] == "medical-ai-backend" {
          grok {
            match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger} - %{GREEDYDATA:message}" }
            overwrite => [ "message" ]
          }
          
          date {
            match => [ "timestamp", "ISO8601" ]
          }
        }
        
        # 解析AI推理日志
        if [kubernetes][container_name] == "ai-inference" {
          grok {
            match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:model_name} - %{DATA:inference_id} - %{GREEDYDATA:message}" }
            overwrite => [ "message" ]
          }
          
          date {
            match => [ "timestamp", "ISO8601" ]
          }
        }
        
        # 解析Nginx访问日志
        if [kubernetes][container_name] == "nginx-frontend" {
          grok {
            match => { "message" => "%{COMBINEDAPACHELOG}" }
          }
          
          date {
            match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
          }
        }
      }
      
      # 添加地理位置信息
      if [clientip] {
        geoip {
          source => "clientip"
          target => "geoip"
        }
      }
      
      # 过滤敏感信息
      mutate {
        gsub => [
          "message", "password=[^\s]+", "password=***",
          "message", "token=[^\s]+", "token=***",
          "message", "key=[^\s]+", "key=***"
        ]
      }
    }
    
    output {
      elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "medical-ai-logs-%{+YYYY.MM.dd}"
        template_name => "medical-ai"
        template_pattern => "medical-ai-*"
        template => "/usr/share/logstash/templates/medical-ai.json"
      }
      
      # 错误日志单独存储
      if [level] == "ERROR" or [level] == "FATAL" {
        elasticsearch {
          hosts => ["elasticsearch:9200"]
          index => "medical-ai-errors-%{+YYYY.MM.dd}"
        }
      }
      
      # 审计日志
      if [logger] == "audit" {
        elasticsearch {
          hosts => ["elasticsearch:9200"]
          index => "medical-ai-audit-%{+YYYY.MM.dd}"
        }
      }
      
      # 性能监控日志
      if [logger] == "performance" {
        elasticsearch {
          hosts => ["elasticsearch:9200"]
          index => "medical-ai-performance-%{+YYYY.MM.dd}"
        }
      }
      
      stdout { codec => rubydebug }
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-settings
  namespace: medical-ai
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline
    path.data: /usr/share/logstash/data
    pipeline.workers: 2
    pipeline.batch.size: 125
    pipeline.batch.delay: 50
    queue.type: memory
    queue.max_events: 0
    queue.max_bytes: 1gb
    dead_letter_queue.enable: true
    log.level: info
    monitoring.elasticsearch.hosts: ["http://elasticsearch:9200"]
---
# Fluentd配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: medical-ai
data:
  fluent.conf: |
    @include systemd.conf
    @include kubernetes.conf
    
    <match **>
      @type elasticsearch
      @id out_es
      @log_level info
      include_tag_key true
      host elasticsearch
      port 9200
      path ""
      scheme http
      ssl_verify false
      ssl_version TLSv1_2
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      log_es_400_reason false
      logstash_prefix medical-ai-fluentd
      logstash_dateformat %Y.%m.%d
      logstash_format true
      index_name medical-ai-fluentd
      type_name _doc
      time_precision 3
      include_timestamp true
      
      <buffer>
        flush_thread_count 8
        flush_interval 5s
        chunk_limit_size 2M
        queue_limit_length 32
        retry_max_interval 30
        retry_forever true
      </buffer>
    </match>
  
  kubernetes.conf: |
    <match fluent.**>
      @type null
    </match>
    
    <source>
      @type tail
      @id in_tail_container_logs
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag raw.kubernetes.*
      read_from_head true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key time
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%N%:z
        </pattern>
      </parse>
    </source>
    
    <match raw.kubernetes.**>
      @type detect_exceptions
      @id detect_exceptions
      remove_tag_prefix raw
      message log
      stream stream
      multiline_flush_interval 5
      max_bytes 500000
      max_lines 1000
    </match>
    
    <filter kubernetes.**>
      @type kubernetes_metadata
      @id filter_kube_metadata
      kubernetes_url "#{ENV['FLUENT_FILTER_KUBERNETES_URL'] || 'https://' + ENV.fetch('KUBERNETES_SERVICE_HOST') + ':' + ENV.fetch('KUBERNETES_SERVICE_PORT') + '/api'}"
      verify_ssl "#{ENV['KUBERNETES_VERIFY_SSL'] || true}"
      ca_file "#{ENV['KUBERNETES_CA_FILE']}"
      skip_labels "#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_LABELS'] || 'false'}"
      skip_container_metadata "#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_CONTAINER_METADATA'] || 'false'}"
      skip_master_url "#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_MASTER_URL'] || 'false'}"
      skip_namespace_metadata "#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_NAMESPACE_METADATA'] || 'false'}"
    </filter>
  
  systemd.conf: |
    <source>
      @type systemd
      @id in_systemd_kubelet
      matches [{ "_SYSTEMD_UNIT": "kubelet.service" }]
      <storage>
        @type local
        persistent true
        path /var/log/fluentd-journald-kubelet.pos
      </storage>
      <entry>
        fields_strip_underscores true
      </entry>
      tag kubelet
    </source>
    
    <source>
      @type systemd
      @id in_systemd_docker
      matches [{ "_SYSTEMD_UNIT": "docker.service" }]
      <storage>
        @type local
        persistent true
        path /var/log/fluentd-journald-docker.pos
      </storage>
      <entry>
        fields_strip_underscores true
      </entry>
      tag docker
    </source>